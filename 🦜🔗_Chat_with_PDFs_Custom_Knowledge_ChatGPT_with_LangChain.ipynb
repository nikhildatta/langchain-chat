{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhildatta/langchain-chat/blob/main/%F0%9F%A6%9C%F0%9F%94%97_Chat_with_PDFs_Custom_Knowledge_ChatGPT_with_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Knowledge ChatGPT with LangChain - Chat with PDFs**\n",
        "\n",
        "**By Liam Ottley:**  [YouTube](https://youtube.com/@LiamOttley)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "0.   Installs, Imports and API Keys\n",
        "1.   Loading PDFs and chunking with LangChain\n",
        "2.   Embedding text and storing embeddings\n",
        "3.   Creating retrieval function\n",
        "4.   Creating chatbot with chat memory (OPTIONAL)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_x1GI7Fo8Y7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Installs, Imports and API Keys"
      ],
      "metadata": {
        "id": "Q24Y-g6h-Bg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CELL FIRST!\n",
        "!pip install -q langchain==0.0.150 pypdf pandas matplotlib tiktoken textract transformers openai faiss-cpu"
      ],
      "metadata": {
        "id": "gk2J2sYYjTkM",
        "outputId": "02440863-3612-42e7-fa74-95e5481258a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/648.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/648.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.4/648.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.8/254.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.22 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import GPT2TokenizerFast\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_transformers import EmbeddingsRedundantFilter\n",
        "from langchain.retrievers.document_compressors import DocumentCompressorPipeline, EmbeddingsFilter\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/\""
      ],
      "metadata": {
        "id": "l-uszlwN641q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a9be886-68ef-44e7-8348-67637bdd0595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "E2Buv5Y0uFr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Loading PDFs and chunking with LangChain"
      ],
      "metadata": {
        "id": "RLULMPXa-Hu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You MUST add your PDF to local files in this notebook (folder icon on left hand side of screen)\n",
        "\n",
        "# Simple method - Split by pages\n",
        "\n",
        "loader = PyPDFLoader(path + \"/attention_is_all_you_need.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "print(pages[0])\n",
        "\n",
        "# SKIP TO STEP 2 IF YOU'RE USING THIS METHOD\n",
        "chunks = pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH546j3nkFwX",
        "outputId": "7ca33ab2-603a-48a0-d212-db22558e3e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Attention Is All You Need\\nAshish Vaswani\\x03\\nGoogle Brain\\navaswani@google.comNoam Shazeer\\x03\\nGoogle Brain\\nnoam@google.comNiki Parmar\\x03\\nGoogle Research\\nnikip@google.comJakob Uszkoreit\\x03\\nGoogle Research\\nusz@google.com\\nLlion Jones\\x03\\nGoogle Research\\nllion@google.comAidan N. Gomez\\x03y\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser\\x03\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin\\x03z\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n\\x03Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\nyWork performed while at Google Brain.\\nzWork performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.' metadata={'source': '/content/drive/MyDrive/Colab Notebooks//attention_is_all_you_need.pdf', 'page': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced method - Split by chunk\n",
        "\n",
        "# Step 1: Convert PDF to text\n",
        "import textract\n",
        "doc = textract.process(path + \"/attention_is_all_you_need.pdf\")\n",
        "\n",
        "# Step 2: Save to .txt and reopen (helps prevent issues)\n",
        "with open('attention_is_all_you_need.txt', 'w') as f:\n",
        "    f.write(doc.decode('utf-8'))\n",
        "\n",
        "with open('attention_is_all_you_need.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Step 3: Create function to count tokens\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "# Step 4: Split text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 300,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = count_tokens,\n",
        "    separators = \". \"\n",
        ")\n",
        "\n",
        "chunks = text_splitter.create_documents([text])"
      ],
      "metadata": {
        "id": "iADY2CXNlNq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick data visualization to ensure chunking was successful\n",
        "\n",
        "# Create a list of token counts\n",
        "token_counts = [count_tokens(chunk.page_content) for chunk in chunks]\n",
        "\n",
        "# Create a DataFrame from the token counts\n",
        "df = pd.DataFrame({'Token Count': token_counts})\n",
        "\n",
        "# Create a histogram of the token count distribution\n",
        "df.hist(bins=40, )\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "fK31bxDOpz1l",
        "outputId": "b4a1b09d-cfc7-4ca8-d827-04d760d7479f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Embed text and store embeddings"
      ],
      "metadata": {
        "id": "_IlznUDK-i2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embedding model\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create vector database\n",
        "db = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "92ObhTAKnZzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Setup retrieval function"
      ],
      "metadata": {
        "id": "2LPwdGDP-nPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check similarity search is working\n",
        "query = \"Who created transformers?\"\n",
        "docs = db.similarity_search(query, k = 10, similarity_threshold=0.76)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWP92zGg5Nb_",
        "outputId": "63a20b4d-8051-42a2-80ea-1f6956a492a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor', metadata={}),\n",
              " Document(page_content='To the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n\\n3 Model Architecture\\n\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 29]', metadata={}),\n",
              " Document(page_content='In all but a few cases [22], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs', metadata={}),\n",
              " Document(page_content='1.\\n\\n7\\n\\n\\x0cTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\n\\nBLEU\\n\\nEN-DE EN-FR\\n23', metadata={}),\n",
              " Document(page_content='6 Results\\n\\n6.1 Machine Translation\\n\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The conﬁguration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs', metadata={}),\n",
              " Document(page_content='In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [8], and observe nearly identical\\nresults to the base model.\\n\\n7 Conclusion\\n\\nIn this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers', metadata={}),\n",
              " Document(page_content='On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\\nsuch as images, audio and video', metadata={}),\n",
              " Document(page_content='The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28', metadata={}),\n",
              " Document(page_content='Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA', metadata={}),\n",
              " Document(page_content='The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n\\n3.1 Encoder and Decoder Stacks\\n\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\n\\n2\\n\\n\\x0cFigure 1: The Transformer - model architecture', metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Create chatbot with chat memory (OPTIONAL)"
      ],
      "metadata": {
        "id": "U_nH1qoL-w--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create conversation chain that uses our vectordb as retriver, this also allows for chat history management\n",
        "relevant_retriever = db.as_retriever()\n",
        "splitter = CharacterTextSplitter(chunk_size=250, chunk_overlap=0, separator=\". \")\n",
        "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
        "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
        "pipeline_compressor = DocumentCompressorPipeline(\n",
        "    transformers=[ splitter, redundant_filter, relevant_filter]\n",
        ")\n",
        "qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.2), relevant_retriever)"
      ],
      "metadata": {
        "id": "evF7_Dyhtcaf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "print(\"Welcome to the Transformers chatbot! Type 'exit' to stop.\")\n",
        "query = input(\"User:\\t\\t\")\n",
        "\n",
        "while query.lower() != \"exit\":\n",
        "\n",
        "    result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "    chat_history.append((query, result['answer']))\n",
        "\n",
        "    print('Chatbot:\\t{answer}\\n'.format(answer = result[\"answer\"]))\n",
        "    query = input(\"User:\\t\\t\")\n",
        "\n",
        "print(\"Thank you for using the Attention Transformer chatbot!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pHw5siewPNt",
        "outputId": "9d99b225-d202-420c-bdfa-32a0ba966971"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Transformers chatbot! Type 'exit' to stop.\n",
            "User:\t\twho created transformers?\n",
            "Chatbot:\tThe Transformers model was created by a team of researchers at Google Brain. The main contributors to the development of the Transformer model are Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin.\n",
            "\n",
            "User:\texplain transformers in 100 words\n",
            "Chatbot:\tTransformers are a type of neural network architecture that have revolutionized natural language processing tasks, such as machine translation. Unlike traditional recurrent or convolutional models, transformers rely on self-attention mechanisms to capture global dependencies between input and output sequences. This allows for more parallelization and faster training. Transformers consist of an encoder-decoder structure, where the encoder maps input sequences to continuous representations, and the decoder generates output sequences. With their ability to handle large inputs and outputs, transformers have achieved state-of-the-art performance in various tasks and have the potential to be applied to other modalities beyond text.\n",
            "\n",
            "User:\texplain transformers in 100 words using only relevant details.\n",
            "Chatbot:\tThe key features and advantages of transformers in natural language processing tasks are:\n",
            "\n",
            "1. Parallelization: Transformers allow for more parallelization compared to recurrent neural networks (RNNs) or convolutional neural networks (CNNs). This means that computations can be performed simultaneously, leading to faster training and inference times.\n",
            "\n",
            "2. Attention Mechanism: Transformers use self-attention mechanisms to capture dependencies between different words in a sentence. This allows the model to focus on relevant words and consider their relationships, regardless of their distance in the input sequence. This attention mechanism helps improve the quality of translation and other sequence transduction tasks.\n",
            "\n",
            "3. State-of-the-art Performance: Transformers have achieved state-of-the-art performance on various natural language processing tasks, including machine translation. They have outperformed previous models, including ensembles, in terms of translation quality.\n",
            "\n",
            "4. Reduced Sequential Computation: Transformers eliminate the need for sequential computation, which is a fundamental constraint in RNNs. This leads to more efficient training and inference, as computations can be performed in parallel.\n",
            "\n",
            "5. Extensibility: Transformers can be extended to handle input and output modalities other than text, such as images, audio, and video. This makes them versatile and applicable to a wide range of tasks.\n",
            "\n",
            "6. Code Availability: The code used to train and evaluate transformer models is available, making it easier for researchers and practitioners to implement and experiment with transformers in their own projects.\n",
            "\n",
            "It's important to note that these advantages are specific to transformers and may not apply to other architectures like RNNs or CNNs.\n",
            "\n",
            "User:\tcan you arrange the names in alphabetical order?\n",
            "Chatbot:\tThe names of the contributors to the development of the Transformer model in alphabetical order are:\n",
            "\n",
            "- Aidan N. Gomez\n",
            "- Ashish Vaswani\n",
            "- Illia Polosukhin\n",
            "- Llion Jones\n",
            "- Lukasz Kaiser\n",
            "- Niki Parmar\n",
            "- Noam Shazeer\n",
            "\n",
            "User:\twhat is attention mechanism?\n",
            "Chatbot:\tThe attention mechanism used in transformers is called self-attention or intra-attention. It allows different positions within a sequence to attend to each other in order to compute a representation of the sequence. This self-attention mechanism is used in various ways within the transformer model, including encoder-decoder attention and self-attention layers in the encoder.\n",
            "\n",
            "User:\texit\n",
            "Thank you for using the Attention Transformer chatbot!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXWmHkyHep62",
        "outputId": "8417869c-9eb9-4ecd-a62c-7a14b6322352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('who created transformers?',\n",
              "  'The Transformers model was created by a team of researchers at Google Brain. The main contributors to the development of the Transformer model are Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin.'),\n",
              " ('explain transformers in 100 words',\n",
              "  'The Transformer is a neural network model that is used for sequence transduction tasks, such as machine translation. It consists of an encoder-decoder structure, where the encoder maps an input sequence to continuous representations, and the decoder generates an output sequence based on these representations. The key innovation of the Transformer is the use of self-attention, which allows the model to capture dependencies between different positions in the input and output sequences. This enables more parallelization and faster training compared to traditional recurrent or convolutional models, leading to state-of-the-art performance on translation tasks.'),\n",
              " ('explain transformers in 100 words using only relevant details.',\n",
              "  \"The key innovations of the Transformer model are:\\n\\n1. Self-Attention Mechanism: The Transformer model uses a self-attention mechanism that allows the model to weigh the importance of different words in the input sequence when generating the output sequence. This mechanism helps the model capture long-range dependencies in the input sequence.\\n\\n2. Encoder-Decoder Architecture: The Transformer model follows an encoder-decoder architecture, where the encoder maps the input sequence to a continuous representation, and the decoder generates the output sequence based on this representation. This architecture allows the model to generate output sequences one element at a time, consuming the previously generated symbols as additional input.\\n\\n3. Stacked Layers: The Transformer model consists of multiple stacked layers in both the encoder and decoder. Each layer has two sub-layers: a multi-head self-attention mechanism and a point-wise, fully connected layer. This stacking of layers helps the model learn more complex representations and capture higher-level dependencies.\\n\\n4. Positional Encoding: The Transformer model uses positional encoding to provide information about the position of each word in the input sequence. This allows the model to take into account the order of words in the sequence, which is important for tasks like machine translation.\\n\\n5. Parallelization: The Transformer model allows for more parallelization compared to recurrent models. This is because the self-attention mechanism in the Transformer can be computed in parallel for all words in the input sequence, whereas recurrent models process words sequentially. This parallelization leads to faster training and inference times.\\n\\nOverall, the Transformer model's key innovations lie in its use of self-attention, encoder-decoder architecture, stacked layers, positional encoding, and improved parallelization compared to previous models.\"),\n",
              " ('can you arrange the names in alphabetical order?',\n",
              "  'The contributors to the development of the Transformer model are:\\n\\n- Aidan N. Gomez\\n- Ashish Vaswani\\n- Illia Polosukhin\\n- Jakob Uszkoreit\\n- Llion Jones\\n- Lukasz Kaiser\\n- Niki Parmar\\n- Noam Shazeer'),\n",
              " ('what is attention mechanism?',\n",
              "  'The attention mechanism used in the Transformer model is called self-attention or intra-attention. It allows different positions within a sequence to attend to each other in order to compute a representation of the sequence. This attention mechanism is used in various tasks, including reading comprehension, summarization, and learning sentence representations.')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077b9914-5b11-43f4-c014-21b992271f9f",
        "id": "nmZxBf_x4IN-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('who created transformers?',\n",
              "  'The Transformer model was created by a team of researchers from Google Brain and Google Research. The main contributors to the development of the Transformer are Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin.'),\n",
              " ('explain transformers in 100 words',\n",
              "  'The Transformer is a network architecture for sequence transduction tasks, such as machine translation. It is based solely on attention mechanisms, eliminating the need for recurrent or convolutional layers. The model was proposed by a team of researchers from Google Brain and Google Research, including Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. The Transformer achieved state-of-the-art results in machine translation tasks, outperforming previous models while being more parallelizable and requiring less training time. The code used to train and evaluate the models is available on GitHub.'),\n",
              " ('explain transformers in 100 words using only relevant details.',\n",
              "  \"The Transformer is a model architecture that uses attention mechanisms to process sequences of data. It consists of an encoder and a decoder, both composed of multiple layers. The encoder maps an input sequence to a sequence of continuous representations, while the decoder generates an output sequence based on the encoder's representations. The key innovation of the Transformer is the use of self-attention, which allows the model to capture dependencies between different positions in the input or output sequences. This enables the Transformer to achieve state-of-the-art performance in tasks like machine translation, while being more parallelizable and faster to train than traditional recurrent models.\"),\n",
              " ('can you arrange the names in alphabetical order?',\n",
              "  'The contributors to the development of the Transformer model are:\\n\\n- Aidan N. Gomez\\n- Ashish Vaswani\\n- Illia Polosukhin\\n- Jakob Uszkoreit\\n- Llion Jones\\n- Łukasz Kaiser\\n- Niki Parmar\\n- Noam Shazeer'),\n",
              " ('whatis attention mechanism?',\n",
              "  'An attention mechanism is a component in neural network models that allows the model to focus on different parts of the input sequence when making predictions. It assigns weights to different parts of the input sequence based on their relevance to the current prediction. This allows the model to selectively attend to important information and ignore irrelevant information. Attention mechanisms have been widely used in tasks such as machine translation, text summarization, and image captioning.')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhjCqlx2fI37",
        "outputId": "696598a9-dd3d-4bf3-ce69-3300b2a8cb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('who created transformers?',\n",
              "  'The Transformer model was created by a team of researchers from Google Brain and Google Research. The main contributors to the development of the Transformer are Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin.'),\n",
              " ('explain transformers in 100 words',\n",
              "  'The Transformer is a neural network architecture that uses attention mechanisms to process sequences of data. Unlike traditional models that rely on recurrent or convolutional layers, the Transformer is based solely on attention mechanisms. This allows for more parallelization and faster training times. The Transformer has achieved state-of-the-art results in tasks such as machine translation, outperforming previous models while requiring less training time. It has been shown to be effective in capturing global dependencies between input and output, making it a powerful tool for sequence transduction tasks.'),\n",
              " ('explain transformers in 100 words using only relevant details.',\n",
              "  'The main advantages of the Transformer model compared to traditional models are:\\n\\n1. Parallelization: The Transformer allows for significantly more parallelization compared to models that use recurrent neural networks (RNNs) or convolutional neural networks (CNNs). This means that the Transformer can process input sequences more efficiently, leading to faster training times.\\n\\n2. Global dependencies: The Transformer uses an attention mechanism to draw global dependencies between input and output. This allows the model to capture long-range dependencies in the data more effectively, which can improve the quality of the generated output.\\n\\n3. Reduced sequential computation: Traditional models, such as those based on RNNs or CNNs, rely on sequential computation, which can be computationally expensive. The Transformer reduces the need for sequential computation by using self-attention, which allows for more efficient processing of input sequences.\\n\\n4. State-of-the-art performance: The Transformer has been shown to achieve state-of-the-art performance on various tasks, including machine translation. It has been able to outperform traditional models, including ensembles, while requiring less training time.\\n\\nOverall, the Transformer offers improved efficiency, better capture of long-range dependencies, and superior performance compared to traditional models.'),\n",
              " ('can you arrange the names in alphabetical order?',\n",
              "  'The contributors to the development of the Transformer model are:\\n\\n- Aidan N. Gomez\\n- Ashish Vaswani\\n- Illia Polosukhin\\n- Jakob Uszkoreit\\n- Llion Jones\\n- Łukasz Kaiser\\n- Niki Parmar\\n- Noam Shazeer'),\n",
              " ('what is attention mechanism?',\n",
              "  'The attention mechanism used in the Transformer model is called self-attention or intra-attention. It allows the model to relate different positions within the same sequence in order to compute a representation of the sequence. This attention mechanism is used in three different ways in the Transformer model: encoder-decoder attention, encoder self-attention, and decoder self-attention.')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2421e6f4-c744-4e6e-a154-17cd50300b1d",
        "id": "jvfukQvY1tAR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('who created transformers?',\n",
              "  'The Transformers model was created by a team of researchers at Google. The key individuals involved in its development are Jakob, Ashish, Illia, Noam, and Niki.'),\n",
              " ('explain transformers in 100 words',\n",
              "  'The Transformer is a model architecture that relies entirely on self-attention to compute representations of its input and output, without using recurrent neural networks (RNNs) or convolution. It allows for more parallelization and has achieved state-of-the-art results in translation quality. The key individuals involved in its development were Jakob, Ashish, Illia, Noam, and Niki. Jakob proposed replacing RNNs with self-attention, while Ashish and Illia designed and implemented the first Transformer models. Noam proposed important components like scaled dot-product attention and multi-head attention. Niki played a crucial role in designing, implementing, tuning, and evaluating various model variants.'),\n",
              " ('explain transformers in 100 words using only relevant details.',\n",
              "  'The key components of the Transformer model are self-attention and an encoder-decoder structure. Self-attention is used to compute representations of the input and output without using RNNs or convolution. The encoder-decoder structure is a common architecture in neural sequence transduction models.\\n\\nThe individuals involved in the development of the Transformer model are Jakob, Ashish, Illia, Noam, and Niki. Jakob proposed the idea of replacing RNNs with self-attention. Ashish and Illia designed and implemented the first Transformer models and were involved in every aspect of the work. Noam proposed scaled dot-product attention, multi-head attention, and the parameter-free position representation. Niki designed, implemented, tuned, and evaluated various model variants.'),\n",
              " ('can you arrange the names in alphabetical order?',\n",
              "  'Noam, Ashish, Illia, Jakob, Niki'),\n",
              " ('can you arrange the names in alphabetical order?',\n",
              "  'Ashish, Illia, Jakob, Noam, Niki'),\n",
              " ('what is attention mechanism?',\n",
              "  'The attention mechanism is a component used in various machine learning models, particularly in sequence modeling and transduction tasks. It allows the model to focus on different parts of the input sequence when making predictions or generating output. The attention mechanism helps the model to capture dependencies between different positions in the input or output sequences, regardless of their distance. It has been successfully used in tasks such as reading comprehension, summarization, textual entailment, and question answering.')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}